{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04e5eac",
   "metadata": {},
   "source": [
    "\n",
    "# Perceptual Hash + Fuzzy Extractor Demo (ResNet‑18 → FE → Crypto Tag)\n",
    "\n",
    "This notebook shows an end-to-end demo:\n",
    "1. Build a **perceptual binary code** `c(x)` from a ResNet-18 embedding (global average pooled) using a random projection and sign quantization.\n",
    "2. Use that code for **Hamming-distance search** over a small image set.\n",
    "3. Apply a **fuzzy extractor** (code-offset construction with Hamming(7,4) blocks) to derive a reproducible secret `R` and helper data `P`.\n",
    "4. Derive a **cryptographic tag** `T` from `R` via HKDF + HMAC-SHA256.\n",
    "\n",
    "> ⚠️ **Notes**\n",
    "> - This is a *research demo*. For production, use stronger ECC (e.g., BCH/LDPC) and careful min-entropy accounting.\n",
    "> - If pretrained weights cannot be fetched (no internet), the model will fall back to random weights (the search won’t be meaningful, but the pipeline runs).\n",
    "> - Put sample images into an `images/` folder (JPEG/PNG).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5233edcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, math, base64, random, hmac, hashlib\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "    from torchvision import transforms\n",
    "    from torchvision.models import resnet18, ResNet18_Weights\n",
    "    TV_OK = True\n",
    "except Exception as e:\n",
    "    TV_OK = False\n",
    "    print(\"torchvision not available:\", e)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854099c",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Image loading\n",
    "Put some images into the `images/` folder. If it's empty, we will generate a few simple synthetic images.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0f1610c-011a-43ae-9af1-606d80f338e0",
   "metadata": {},
   "source": [
    "# code for steaganography to file\n",
    "echo -n \"hello world!\" > msg.txt\n",
    "steghide embed \\\n",
    "  -cf images/0.07180100_1442390923_.jpg \\   # cover file (исходное изображение)\n",
    "  -ef msg.txt \\                              # файл с сообщением\n",
    "  -sf images/0.07180100_1442390923_stegano.jpg \\  # куда сохранить\n",
    "  -p \"strong-passphrase\"                     # пароль (нужен для извлечения)\n",
    "steghide extract \\\n",
    "  -sf images/0.07180100_1442390923_stegano.jpg \\\n",
    "  -xf out.txt \\\n",
    "  -p \"strong-passphrase\"\n",
    "\n",
    "cat out.txt   # должно напечатать: hello world!\n",
    "# code change file \n",
    "magick images/0.07180100_1442390923_.jpg -modulate 100,90,100 -resize 90%  images/0.07180100_1442390923_changed.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbee24-0043-48ba-8ee0-b9487b6a2bc9",
   "metadata": {},
   "source": [
    "из исходного файла images/0.07180100_1442390923_.jpg получаем:\n",
    "* images/0.07180100_1442390923_stegano.jpg - с встроенной стеганографией (отдельные пиксели)\n",
    "* images/0.07180100_1442390923_changed.jpg - с уменьшненой а 10% цветностью и размером (все пиксели) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96f4e81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,\n",
       " [PosixPath('images/0.07180100_1442390923_.jpg'),\n",
       "  PosixPath('images/0.07180100_1442390923_changed.jpg'),\n",
       "  PosixPath('images/0.07180100_1442390923_stegano.jpg'),\n",
       "  PosixPath('images/012038.jpg'),\n",
       "  PosixPath('images/014-taal-crater-lake_586DA81BD8A34008B4CFFA1B2E206AFF.jpg')])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "IMG_DIR = Path(\"images\")\n",
    "IMG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def load_images_from_folder(folder: Path, max_count: int = 64) -> List[Path]:\n",
    "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
    "    files = [p for p in folder.iterdir() if p.suffix.lower() in exts]\n",
    "    files.sort()\n",
    "    return files[:max_count]\n",
    "\n",
    "image_paths = load_images_from_folder(IMG_DIR, max_count=200)\n",
    "\n",
    "# Fallback: create a few synthetic images if none provided\n",
    "def make_synthetic_images(folder: Path, n: int = 6):\n",
    "    colors = [(255,0,0), (0,255,0), (0,0,255),\n",
    "              (255,255,0), (255,0,255), (0,255,255)]\n",
    "    for i in range(n):\n",
    "        img = Image.new(\"RGB\", (224,224), colors[i % len(colors)])\n",
    "        # simple pattern: add a small rectangle\n",
    "        for x in range(80, 144):\n",
    "            for y in range(100 + (i%3)*5, 160 + (i%3)*5):\n",
    "                img.putpixel((x,y), tuple(255 - c for c in colors[i % len(colors)]))\n",
    "        img.save(folder / f\"synthetic_{i:02d}.png\")\n",
    "\n",
    "if not image_paths:\n",
    "    print(\"No images found in 'images/'. Creating a few synthetic examples...\")\n",
    "    make_synthetic_images(IMG_DIR, n=6)\n",
    "    image_paths = load_images_from_folder(IMG_DIR, max_count=64)\n",
    "\n",
    "len(image_paths), image_paths[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3daa0",
   "metadata": {},
   "source": [
    "\n",
    "## 2) ResNet-18 embedding\n",
    "We take global-average-pooled features (`d=512`). If pretrained weights are available, we use them; otherwise, we use random weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45f4f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim: 512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ResNet18Embed(nn.Module):\n",
    "    def __init__(self, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        if TV_OK:\n",
    "            if pretrained:\n",
    "                try:\n",
    "                    m = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "                except Exception as e:\n",
    "                    print(\"Failed to load pretrained weights, falling back to random:\", e)\n",
    "                    m = resnet18(weights=None)\n",
    "            else:\n",
    "                m = resnet18(weights=None)\n",
    "            # remove classifier head; keep avgpool\n",
    "            self.backbone = nn.Sequential(*(list(m.children())[:-1]))  # up to avgpool\n",
    "            self.out_dim = 512\n",
    "        else:\n",
    "            # Minimal fallback: a tiny conv net (not meaningful)\n",
    "            self.backbone = nn.Sequential(\n",
    "                nn.Conv2d(3,16,3,1,1), nn.ReLU(), nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "            self.out_dim = 16\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        feat = self.backbone(x)  # [B, d, 1, 1]\n",
    "        feat = feat.view(feat.size(0), -1)  # [B, d]\n",
    "        feat = F.normalize(feat, p=2, dim=1)\n",
    "        return feat\n",
    "\n",
    "# preprocessing\n",
    "if TV_OK:\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "else:\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "embedder = ResNet18Embed(pretrained=True).to(device).eval()\n",
    "print(\"Embedding dim:\", embedder.out_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74345671",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Perceptual binary code: random projection + sign\n",
    "We project to `n_bits` with a fixed Gaussian matrix `A` and threshold at zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dcc3954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Choose n_bits for the code\n",
    "n_bits = 512  # can be 256..2048 depending on speed/needs\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "A = rng.standard_normal((n_bits, embedder.out_dim)).astype(np.float32)\n",
    "b = np.zeros((n_bits,), dtype=np.float32)  # optional bias\n",
    "\n",
    "A_t = torch.from_numpy(A).to(device)\n",
    "b_t = torch.from_numpy(b).to(device)\n",
    "\n",
    "def image_to_code(path: Path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = preprocess(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        v = embedder(x)                        # [1, d], L2-normalized\n",
    "        z = F.linear(v, A_t, b_t)              # [1, n_bits]\n",
    "    c = (z.cpu().numpy()[0] >= 0).astype(np.uint8)  # {0,1}^n\n",
    "    return c, z.cpu().numpy()[0], v.cpu()\n",
    "\n",
    "def hamming(a: np.ndarray, b: np.ndarray) -> int:\n",
    "    return int(np.sum(a.astype(np.uint8) ^ b.astype(np.uint8)))\n",
    "\n",
    "# Encode all images\n",
    "db = []\n",
    "for p in image_paths:\n",
    "    c, z, v = image_to_code(p)\n",
    "    db.append({\"path\": str(p), \"code\": c, \"embed\": z})\n",
    "\n",
    "len(db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07d694",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Similarity search (Hamming)\n",
    "Compute Hamming distances from a query to the database and list nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "973817cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'images/0.07180100_1442390923_.jpg'),\n",
       " (1, 'images/0.07180100_1442390923_stegano.jpg'),\n",
       " (9, 'images/0.07180100_1442390923_changed.jpg'),\n",
       " (69, 'images/a5f17e0b3dd5ed56bf5744f600b5c28b.jpg'),\n",
       " (86, 'images/a-golden-bedroom-with-a-feng-shui-glow.jpg')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def search_nearest(query_code: np.ndarray, topk: int = 5):\n",
    "    scores = []\n",
    "    for row in db:\n",
    "        d = hamming(query_code, row[\"code\"])\n",
    "        scores.append((d, row[\"path\"]))\n",
    "    scores.sort(key=lambda x: x[0])\n",
    "    return scores[:topk]\n",
    "\n",
    "q_code, _, _ = image_to_code(Path(db[0][\"path\"]))\n",
    "top = search_nearest(q_code, topk=5)\n",
    "top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064898f",
   "metadata": {},
   "source": [
    "## 5) Fuzzy extractor (code-offset) with Hamming(7,4) blocks\n",
    "Основные функции:\n",
    "\n",
    "**`fe_gen(c_bits, blocks=64)`** → возвращает `dict` с:\n",
    "\n",
    "* `helper_P` — публичный *helper* $P$ (биты упакованы и закодированы Base64);\n",
    "* `R_hex` — хэш-секрет $R=\\mathrm{SHA256}(w)$ в hex (в демо хранится для проверки);\n",
    "* `K_hex` — ключ $K=\\mathrm{HKDF}(R,\\text{\"FE-demo\"})$ в hex (из него потом считают тег/HMAC);\n",
    "* `blocks` — число 7-битовых кодовых блоков Хэмминга;\n",
    "* `L` — сколько бит кода использовано $(L=7\\cdot \\text{blocks})$.\n",
    "\n",
    "**`fe_rep(c_bits, helper)`** → возвращает `dict` с:\n",
    "\n",
    "* `corrected_blocks` — сколько 7-битовых блоков исправил декодер Хэмминга;\n",
    "* `R_hex` — восстановленный $R$ в hex;\n",
    "* `K_hex` — восстановленный $K$ в hex;\n",
    "* `match` — булево, совпал ли восстановленный $R$ с эталоном из `helper` (успех репродукции).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1167dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, base64, hmac, hashlib\n",
    "\n",
    "# Hamming(7,4)\n",
    "G = np.array([\n",
    "    [1,0,0,0, 0,1,1],\n",
    "    [0,1,0,0, 1,0,1],\n",
    "    [0,0,1,0, 1,1,0],\n",
    "    [0,0,0,1, 1,1,1],\n",
    "], dtype=np.uint8)\n",
    "\n",
    "H = np.array([\n",
    "    [1,1,0,1, 1,0,0],\n",
    "    [1,0,1,1, 0,1,0],\n",
    "    [0,1,1,1, 0,0,1],\n",
    "], dtype=np.uint8)\n",
    "\n",
    "syndrome_to_bit = {\n",
    "    (1,0,0): 4, (0,1,0): 5, (0,0,1): 6,\n",
    "    (1,1,0): 0, (1,0,1): 1, (0,1,1): 2, (1,1,1): 3,\n",
    "}\n",
    "\n",
    "def ham_encode_block(m4):\n",
    "    cw = (m4 @ G) % 2\n",
    "    return cw.astype(np.uint8)\n",
    "\n",
    "def ham_decode_block(y7):\n",
    "    s = (H @ y7) % 2\n",
    "    key = tuple(int(x) for x in s.tolist())\n",
    "    corrected = False\n",
    "    cw = y7.copy()\n",
    "    if key != (0,0,0):\n",
    "        pos = syndrome_to_bit.get(key, None)\n",
    "        if pos is not None:\n",
    "            cw[pos] ^= 1\n",
    "            corrected = True\n",
    "    return cw, corrected\n",
    "\n",
    "def ham_extract_message(cw7):\n",
    "    return cw7[:4].astype(np.uint8)\n",
    "\n",
    "def ham_encode_message(m_bits):\n",
    "    assert m_bits.ndim == 1 and (len(m_bits) % 4 == 0)\n",
    "    out = []\n",
    "    for i in range(0, len(m_bits), 4):\n",
    "        out.append(ham_encode_block(m_bits[i:i+4]))\n",
    "    return np.concatenate(out, axis=0).astype(np.uint8)\n",
    "\n",
    "def ham_decode_codeword(y_bits):\n",
    "    assert y_bits.ndim == 1 and (len(y_bits) % 7 == 0)\n",
    "    out = []; corrected = 0\n",
    "    for i in range(0, len(y_bits), 7):\n",
    "        cw, corr = ham_decode_block(y_bits[i:i+7])\n",
    "        out.append(cw); corrected += int(corr)\n",
    "    return np.concatenate(out, axis=0).astype(np.uint8), corrected\n",
    "\n",
    "def bits_to_bytes(bs: np.ndarray) -> bytes:\n",
    "    pad = (-len(bs)) % 8\n",
    "    if pad: bs = np.concatenate([bs, np.zeros(pad, dtype=np.uint8)])\n",
    "    return np.packbits(bs, bitorder='big').tobytes()\n",
    "\n",
    "def sha256_hex(data: bytes) -> str:\n",
    "    return hashlib.sha256(data).hexdigest()\n",
    "\n",
    "def hkdf_extract_expand(key_material: bytes, info: bytes = b'ctx', out_len: int = 32) -> bytes:\n",
    "    prk = hmac.new(b'\\x00'*32, key_material, hashlib.sha256).digest()\n",
    "    t = b''; okm = b''; counter = 1\n",
    "    while len(okm) < out_len:\n",
    "        t = hmac.new(prk, t + info + bytes([counter]), hashlib.sha256).digest()\n",
    "        okm += t; counter += 1\n",
    "    return okm[:out_len]\n",
    "\n",
    "def fe_gen(c_bits: np.ndarray, blocks: int = 64):\n",
    "    L = 7 * blocks\n",
    "    x = (np.array(c_bits[:L], dtype=np.uint8) & 1)\n",
    "\n",
    "    # 1) На этапе Gen СНАЧАЛА «нормализуем» каждый 7-битный блок до ближайшего кодового слова\n",
    "    #    (ровно тем же декодером, что будет у Rep)\n",
    "    code, corrected_gen = ham_decode_codeword(x)  # длина L, исправляет ≤1 ошибку на блок\n",
    "\n",
    "    # 2) Offset = code ^ x (ровно под тот же 'code', который мы только что зафиксировали)\n",
    "    P_bits  = (code ^ x).astype(np.uint8)\n",
    "    P_bytes = np.packbits(P_bits, bitorder='big').tobytes()\n",
    "    helper_P_b64 = base64.b64encode(P_bytes).decode('ascii')\n",
    "\n",
    "    # 3) Материал привязки и ключ — от ИМЕННО ЭТОГО 'code'\n",
    "    R_hex = hashlib.sha256(bits_to_bytes(code)).hexdigest()\n",
    "    K_hex = hkdf_extract_expand(bytes.fromhex(R_hex), info=b'FE-demo', out_len=32).hex()\n",
    "\n",
    "    return {\n",
    "        \"blocks\": blocks,\n",
    "        \"L\": L,\n",
    "        \"helper_P\": helper_P_b64,\n",
    "        \"R_hex\": R_hex,\n",
    "        \"K_hex\": K_hex,\n",
    "        \"corrected_blocks_enroll\": int(corrected_gen),  # полезно для дебага\n",
    "    }\n",
    "\n",
    "def fe_rep(c_bits: np.ndarray, helper):\n",
    "    L = int(helper[\"L\"])\n",
    "    x = (np.array(c_bits[:L], dtype=np.uint8) & 1)\n",
    "\n",
    "    P_bytes = base64.b64decode(helper[\"helper_P\"])\n",
    "    P_arr   = np.frombuffer(P_bytes, dtype=np.uint8)\n",
    "    P_bits  = np.unpackbits(P_arr, bitorder='big')[:L]\n",
    "\n",
    "    # y = code ⊕ noise  (при нулевом шуме будет ровно code)\n",
    "    y = (x ^ P_bits).astype(np.uint8)\n",
    "\n",
    "    # декодируем до ближайшего кодового слова тем же алгоритмом\n",
    "    y_dec, corrected = ham_decode_codeword(y)\n",
    "\n",
    "    R_hex = hashlib.sha256(bits_to_bytes(y_dec)).hexdigest()\n",
    "    K_hex = hkdf_extract_expand(bytes.fromhex(R_hex), info=b'FE-demo', out_len=32).hex()\n",
    "\n",
    "    ok = (R_hex == helper[\"R_hex\"])\n",
    "    return {\"corrected_blocks\": int(corrected), \"R_hex\": R_hex, \"K_hex\": K_hex, \"match\": ok}\n",
    "\n",
    "\n",
    "\n",
    "def hmac_sha256_hex(key: bytes, msg: bytes) -> str:\n",
    "    return hmac.new(key, msg, hashlib.sha256).hexdigest()\n",
    "\n",
    "def derive_tag_from_helper(helper, meta: str = \"record:0\") -> str:\n",
    "    K = bytes.fromhex(helper[\"K_hex\"])\n",
    "    return hmac_sha256_hex(K, meta.encode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c8825",
   "metadata": {},
   "source": [
    "\n",
    "### Demo FE on one entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a72b99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper: {'blocks': 64, 'L': 448, 'helper_P': 'QARAIDAICCECAQAgSAQIAACASAIIAAARCAgAkICACCAhAAQIBQEBEAEICABCAICCEAQAIAgICEA=', 'R_hex': '753c2a53de4366e6324058091e5a4c1351a45f1e27c36f6b208ce057559645b7', 'K_hex': '9d3e214924bc0692cea4441356677bd28b828f703de16a22b82a3fffa3375c16', 'corrected_blocks_enroll': 56}\n",
      "Repair для того же Img: {'corrected_blocks': 0, 'R_hex': '753c2a53de4366e6324058091e5a4c1351a45f1e27c36f6b208ce057559645b7', 'K_hex': '9d3e214924bc0692cea4441356677bd28b828f703de16a22b82a3fffa3375c16', 'match': True}\n",
      "Tag: 97057546884f988e0888b3bcd2f4e22fdce9764c162d3e02e80c756f3a100b57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c0 = db[0][\"code\"]\n",
    "helper0 = fe_gen(c0, blocks=64)  # uses first 448 bits\n",
    "rep0 = fe_rep(c0, helper0)\n",
    "T0 = derive_tag_from_helper(helper0, meta=\"record:0\")\n",
    "print(f\"Helper: {helper0}\")\n",
    "print(f\"Repair для того же Img: {rep0}\")\n",
    "print(f\"Tag: {T0}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516de79f",
   "metadata": {},
   "source": [
    "\n",
    "### Perturbation test (flip one bit per block across 10 blocks)\n",
    "пробуем портить бинарное представление, восстанавливаем и срваниваем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "147b8db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper original: {'blocks': 64, 'L': 448, 'helper_P': 'QARAIDAICCECAQAgSAQIAACASAIIAAARCAgAkICACCAhAAQIBQEBEAEICABCAICCEAQAIAgICEA=', 'R_hex': '753c2a53de4366e6324058091e5a4c1351a45f1e27c36f6b208ce057559645b7', 'K_hex': '9d3e214924bc0692cea4441356677bd28b828f703de16a22b82a3fffa3375c16', 'corrected_blocks_enroll': 56}\n",
      "Repaired flipped: {'corrected_blocks': 10, 'R_hex': '753c2a53de4366e6324058091e5a4c1351a45f1e27c36f6b208ce057559645b7', 'K_hex': '9d3e214924bc0692cea4441356677bd28b828f703de16a22b82a3fffa3375c16', 'match': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def flip_bits(bits: np.ndarray, idxs):\n",
    "    b = bits.copy()\n",
    "    for i in idxs:\n",
    "        if 0 <= i < len(b): b[i] ^= 1\n",
    "    return b\n",
    "\n",
    "c_perturb = c0.copy()\n",
    "for blk in range(10):\n",
    "    pos = blk*7 + (blk % 7)\n",
    "    c_perturb[pos] ^= 1\n",
    "    # c_perturb[pos+1] ^= 1 ## 2 ошибки в одном блоке\n",
    "\n",
    "rep1 = fe_rep(c_perturb, helper0)\n",
    "print(f\"Helper original: {helper0}\")\n",
    "print(f\"Repaired flipped: {rep1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335872a",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Whole DB: build helpers/tags, search + verify\n",
    "* в БД достаточно хранить Значения helper0[\"helper_P\"] и T0 (см пп \"Demo FE on one entry\"). Для поиска и верификации этого достаточно, если нужно безопасно. Для эффективного поиска нужен отдельный индекс по коду (напр., c(x)/LSH), иначе будет O(N).\n",
    "\n",
    "* И это не эквивалент классическому хешированию, сопоставимый по надёжности, но формально другой примитив.\n",
    "По подделке/целостности не хуже (HMAC даёт криптостойкость уровня хешей), но по приватности слабее классического безключевого хеша, т.к. публичный helper несёт ограниченную утечку и позволяет проверки принадлежности — это осознанный компромисс ради поиска (ради этого и задумано исследование).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "914d8bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare images from DB with img images/0.07180100_1442390923_.jpg\n",
      "===\n",
      "--check record 0 from DB\n",
      "   record math: {'path': 'images/0.07180100_1442390923_.jpg', 'ham': 0, 'FE_match': True, 'tag_q': '97057546884f988e0888b3bcd2f4e22fdce9764c162d3e02e80c756f3a100b57', 'row_tag': '97057546884f988e0888b3bcd2f4e22fdce9764c162d3e02e80c756f3a100b57', 'verified': True}\n",
      "--check record 2 from DB\n",
      "   record math: {'path': 'images/0.07180100_1442390923_stegano.jpg', 'ham': 1, 'FE_match': True, 'tag_q': '1f69538518666a149a280f57e4ae168d887ffefdef64c289cdb02560e7c0cedd', 'row_tag': '1f69538518666a149a280f57e4ae168d887ffefdef64c289cdb02560e7c0cedd', 'verified': True}\n",
      "--check record 1 from DB\n",
      "   record math: {'path': 'images/0.07180100_1442390923_changed.jpg', 'ham': 9, 'FE_match': True, 'tag_q': 'cb20bdfdf1c5f1a59311503f04180cdf33a600eb889f2408330952a5102f2f80', 'row_tag': 'cb20bdfdf1c5f1a59311503f04180cdf33a600eb889f2408330952a5102f2f80', 'verified': True}\n",
      "--check record 138 from DB\n",
      "   record not match: {'path': 'images/a5f17e0b3dd5ed56bf5744f600b5c28b.jpg', 'ham': 69, 'FE_match': False, 'tag_q': '74f02de15eb80cef1b663fbb2caf6389f7d8b08d8544942df7b195167d659b20', 'row_tag': 'bb4da10a95ff3850801f0c7691bf327bed63a546cc9709bdb78296b11f9acca7', 'verified': False}\n",
      "--check record 136 from DB\n",
      "   record not match: {'path': 'images/a-golden-bedroom-with-a-feng-shui-glow.jpg', 'ham': 86, 'FE_match': False, 'tag_q': '18ba84769ff71ff37e549f7e14cb6ae2fde4ea5c55b4ba25c412e677a481a72d', 'row_tag': '7078e4db550fc9ce71b267dff81b49363087b07e9b16309a359031ea72793be9', 'verified': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build FE helper + tag for each DB entry\n",
    "for i,row in enumerate(db):\n",
    "    c = row[\"code\"]\n",
    "    helper = fe_gen(c, blocks=64)\n",
    "    row[\"fe_helper\"] = helper\n",
    "    row[\"tag\"] = derive_tag_from_helper(helper, meta=f\"record:{i}\")\n",
    "\n",
    "# Query\n",
    "q_code, _, _ = image_to_code(Path(db[0][\"path\"]))\n",
    "cands = []\n",
    "for row in db:\n",
    "    d = hamming(q_code, row[\"code\"])\n",
    "    cands.append((d, row))\n",
    "cands.sort(key=lambda x: x[0])\n",
    "cands = cands[:5]\n",
    "\n",
    "print(f'Compare images from DB with img {Path(db[0][\"path\"])}\\n===')\n",
    "results = []\n",
    "for d, row in cands:\n",
    "    rep = fe_rep(q_code, row[\"fe_helper\"])\n",
    "    tag_q = hmac_sha256_hex(bytes.fromhex(rep[\"K_hex\"]), f\"record:{db.index(row)}\".encode())\n",
    "    verified = (tag_q == row[\"tag\"]) and rep[\"match\"]\n",
    "    results.append({\"path\": row[\"path\"], \"ham\": d, \"FE_match\": rep[\"match\"], \"tag_q\":tag_q, \"row_tag\":row[\"tag\"], \"verified\": verified})\n",
    "    print(f\"--check record {db.index(row)} from DB\")\n",
    "    report = {\"path\": row[\"path\"], \"ham\": d, \"FE_match\": rep[\"match\"], \"tag_q\":tag_q, \"row_tag\":row[\"tag\"], \"verified\": verified}\n",
    "    print(f'   record {\"math\" if report[\"verified\"] else \"not match\"}: {report}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1435f35-31a3-4d91-a6f3-507e3c977512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mipt_",
   "language": "python",
   "name": "mipt_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
